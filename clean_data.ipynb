{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1e84c040-637e-4a51-85ca-defd90a684f5",
   "metadata": {},
   "source": [
    "This script divides data from the original Kaggle dataset (https://www.kaggle.com/datasets/unclesamulus/blood-cells-image-dataset/data) into train, test, and validate sets with an 80/10/10 split. It also removes images that do not match the expected 360 x 363 image size (around 500), leaving about 16,500 images.\n",
    "\n",
    "When downloaded from Kaggle, the directory structure looks like this:\n",
    "\n",
    "archive/\n",
    "|-- bloodcells_dataset/\n",
    "|   |-- basophil/\n",
    "|   |   |-- BA_47.jpg\n",
    "|   |   |-- ...\n",
    "|   |-- eosinophil/\n",
    "|   |   |-- EO_27.jpg\n",
    "|   |   |-- ...\n",
    "|   |-- erythroblast/\n",
    "|   |   |-- ERB_233.jpg\n",
    "|   |   |-- ...\n",
    "|   |-- ig/\n",
    "|   |   |-- IG_5887.jpg\n",
    "|   |   |-- ...\n",
    "|   |-- lymphocyte/\n",
    "|   |   |-- LY_3530.jpg\n",
    "|   |   |-- ...\n",
    "|   |-- monocyte/\n",
    "|   |   |-- MO_1524.jpg\n",
    "|   |   |-- ...\n",
    "|   |-- neutrophil/\n",
    "|   |   |-- BNE_715.jpg\n",
    "|   |   |-- ...\n",
    "|   |-- platelet/\n",
    "|   |   |-- PLATELET_344.jpg\n",
    "|   |   |-- ...\n",
    "\n",
    "Below is the directory structure the script creates:\n",
    "\n",
    "data/\n",
    "|-- test\n",
    "|   |-- basophil/\n",
    "|   |   |-- BA_25610.jpg\n",
    "|   |   |-- ...\n",
    "|   |-- ...\n",
    "|-- train\n",
    "|   |-- basophil/\n",
    "|   |   |-- BA_47.jpg\n",
    "|   |   |-- ...\n",
    "|   |-- ...\n",
    "|-- validate\n",
    "|   |-- basophil/\n",
    "|   |   |-- BA_20201.jpg\n",
    "|   |   |-- ...\n",
    "|   |-- ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d12e6b8-d5f0-4b94-9e8d-4b96f572f6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source directory: archive/bloodcells_dataset\n",
      "Target directory: data\n",
      "Splitting data: Train 80.0%, Test 10.0%, Validate 10.0%\n",
      "Filtering images to keep only dimensions (WxH): (360, 363)\n",
      "------------------------------\n",
      "Found classes: basophil, eosinophil, erythroblast, ig, lymphocyte, monocyte, neutrophil, platelet\n",
      "\n",
      "Processing class: basophil...\n",
      "  Found 1218 potential image files.\n",
      "  Validating dimensions (target: (360, 363))...\n",
      "  Finished validation: Kept=1168, Removed=50 (dimension), Error=0 (read).\n",
      "  Splitting 1168 valid images into: Train=934, Test=116, Validate=118\n",
      "  Files copied: Train=934, Test=116, Validate=118\n",
      "\n",
      "Processing class: eosinophil...\n",
      "  Found 3117 potential image files.\n",
      "  Validating dimensions (target: (360, 363))...\n",
      "  Finished validation: Kept=3067, Removed=50 (dimension), Error=0 (read).\n",
      "  Splitting 3067 valid images into: Train=2453, Test=306, Validate=308\n",
      "  Files copied: Train=2453, Test=306, Validate=308\n",
      "\n",
      "Processing class: erythroblast...\n",
      "  Found 1551 potential image files.\n",
      "  Validating dimensions (target: (360, 363))...\n",
      "  Finished validation: Kept=1499, Removed=52 (dimension), Error=0 (read).\n",
      "  Splitting 1499 valid images into: Train=1199, Test=149, Validate=151\n",
      "  Files copied: Train=1199, Test=149, Validate=151\n",
      "\n",
      "Processing class: ig...\n",
      "  Found 2895 potential image files.\n",
      "  Validating dimensions (target: (360, 363))...\n",
      "  Finished validation: Kept=2744, Removed=151 (dimension), Error=0 (read).\n",
      "  Splitting 2744 valid images into: Train=2195, Test=274, Validate=275\n",
      "  Files copied: Train=2195, Test=274, Validate=275\n",
      "\n",
      "Processing class: lymphocyte...\n",
      "  Found 1214 potential image files.\n",
      "  Validating dimensions (target: (360, 363))...\n",
      "  Finished validation: Kept=1164, Removed=50 (dimension), Error=0 (read).\n",
      "  Splitting 1164 valid images into: Train=931, Test=116, Validate=117\n",
      "  Files copied: Train=931, Test=116, Validate=117\n",
      "\n",
      "Processing class: monocyte...\n",
      "  Found 1420 potential image files.\n",
      "  Validating dimensions (target: (360, 363))...\n",
      "  Finished validation: Kept=1370, Removed=50 (dimension), Error=0 (read).\n",
      "  Splitting 1370 valid images into: Train=1096, Test=137, Validate=137\n",
      "  Files copied: Train=1096, Test=137, Validate=137\n",
      "\n",
      "Processing class: neutrophil...\n",
      "  Found 3329 potential image files.\n",
      "  Validating dimensions (target: (360, 363))...\n",
      "  Finished validation: Kept=3279, Removed=50 (dimension), Error=0 (read).\n",
      "  Splitting 3279 valid images into: Train=2623, Test=327, Validate=329\n",
      "  Files copied: Train=2623, Test=327, Validate=329\n",
      "\n",
      "Processing class: platelet...\n",
      "  Found 2348 potential image files.\n",
      "  Validating dimensions (target: (360, 363))...\n",
      "  Finished validation: Kept=2348, Removed=0 (dimension), Error=0 (read).\n",
      "  Splitting 2348 valid images into: Train=1878, Test=234, Validate=236\n",
      "  Files copied: Train=1878, Test=234, Validate=236\n",
      "\n",
      "==============================\n",
      "Processing Complete!\n",
      "==============================\n",
      "Total potential image files processed: 17092\n",
      "Total files removed (dimension mismatch): 453\n",
      "Total files removed (error reading):    0\n",
      "Total valid files kept and split:       16639\n",
      "------------------------------\n",
      "\n",
      "Dataset successfully split into Train/Test/Validate sets within the 'data' directory using only images with dimensions (360, 363).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "# --- Configuration ---\n",
    "SOURCE_BASE_DIR = 'archive/bloodcells_dataset'\n",
    "TARGET_BASE_DIR = 'data'\n",
    "SPLIT_RATIOS = {'train': 0.8, 'test': 0.1, 'validate': 0.1}\n",
    "EXPECTED_DIMS = (360, 363) # Pillow uses (width, height)\n",
    "\n",
    "# --- Sanity Checks ---\n",
    "if not os.path.isdir(SOURCE_BASE_DIR):\n",
    "    print(f\"Error: Source directory '{SOURCE_BASE_DIR}' not found.\")\n",
    "    exit()\n",
    "\n",
    "if abs(sum(SPLIT_RATIOS.values()) - 1.0) > 1e-9:\n",
    "     print(f\"Error: Split ratios must sum to 1.0. Current sum: {sum(SPLIT_RATIOS.values())}\")\n",
    "     exit()\n",
    "\n",
    "# --- Setup ---\n",
    "print(f\"Source directory: {SOURCE_BASE_DIR}\")\n",
    "print(f\"Target directory: {TARGET_BASE_DIR}\")\n",
    "print(f\"Splitting data: Train {SPLIT_RATIOS['train']*100}%, \"\n",
    "      f\"Test {SPLIT_RATIOS['test']*100}%, \"\n",
    "      f\"Validate {SPLIT_RATIOS['validate']*100}%\")\n",
    "print(f\"Filtering images to keep only dimensions (WxH): {EXPECTED_DIMS}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Create base target directories if they don't exist\n",
    "for split_name in SPLIT_RATIOS.keys():\n",
    "    os.makedirs(os.path.join(TARGET_BASE_DIR, split_name), exist_ok=True)\n",
    "\n",
    "total_files_processed = 0\n",
    "total_files_kept = 0\n",
    "total_files_removed_dimension = 0\n",
    "total_files_error_reading = 0\n",
    "removed_file_details = [] # Store details of removed files: (filepath, reason, details)\n",
    "\n",
    "# --- Get Class Names ---\n",
    "try:\n",
    "    class_names = [d for d in os.listdir(SOURCE_BASE_DIR) if os.path.isdir(os.path.join(SOURCE_BASE_DIR, d))]\n",
    "    if not class_names:\n",
    "        print(f\"Error: No subdirectories (classes) found in {SOURCE_BASE_DIR}\")\n",
    "        exit()\n",
    "    print(f\"Found classes: {', '.join(class_names)}\")\n",
    "except OSError as e:\n",
    "    print(f\"Error accessing source directory {SOURCE_BASE_DIR}: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Process Each Class ---\n",
    "for class_name in class_names:\n",
    "    print(f\"\\nProcessing class: {class_name}...\")\n",
    "    source_class_dir = os.path.join(SOURCE_BASE_DIR, class_name)\n",
    "\n",
    "    # --- Create Target Class Directories ---\n",
    "    target_dirs = {}\n",
    "    for split_name in SPLIT_RATIOS.keys():\n",
    "        target_dir = os.path.join(TARGET_BASE_DIR, split_name, class_name)\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        target_dirs[split_name] = target_dir\n",
    "\n",
    "    # --- List All Potential Image Files ---\n",
    "    try:\n",
    "        all_files_in_class = [\n",
    "            f for f in os.listdir(source_class_dir)\n",
    "            if os.path.isfile(os.path.join(source_class_dir, f)) and\n",
    "               f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tif', '.tiff'))\n",
    "        ]\n",
    "        if not all_files_in_class:\n",
    "            print(f\"  Warning: No image files found in {source_class_dir}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Found {len(all_files_in_class)} potential image files.\")\n",
    "        total_files_processed += len(all_files_in_class)\n",
    "\n",
    "    except OSError as e:\n",
    "        print(f\"  Error listing files in {source_class_dir}: {e}. Skipping class.\")\n",
    "        continue\n",
    "        \n",
    "    # --- Filter Files by Dimension ---\n",
    "    valid_files = []\n",
    "    class_removed_dimension = 0\n",
    "    class_error_reading = 0\n",
    "    \n",
    "    print(f\"  Validating dimensions (target: {EXPECTED_DIMS})...\")\n",
    "    for filename in all_files_in_class:\n",
    "        source_path = os.path.join(source_class_dir, filename)\n",
    "        try:\n",
    "            with Image.open(source_path) as img:\n",
    "                if img.size == EXPECTED_DIMS:\n",
    "                    valid_files.append(filename)\n",
    "                else:\n",
    "                    # print(f\"    Removing '{filename}': Incorrect dimensions ({img.size})\")\n",
    "                    class_removed_dimension += 1\n",
    "                    removed_file_details.append((source_path, \"Dimension Mismatch\", img.size))\n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR: Cannot read image '{filename}': {e}. Removing from consideration.\")\n",
    "            class_error_reading += 1\n",
    "            removed_file_details.append((source_path, \"Read Error\", str(e)))\n",
    "\n",
    "    total_files_kept += len(valid_files)\n",
    "    total_files_removed_dimension += class_removed_dimension\n",
    "    total_files_error_reading += class_error_reading\n",
    "\n",
    "    if not valid_files:\n",
    "        print(f\"  No valid images found for class '{class_name}' after filtering. Skipping splitting for this class.\")\n",
    "        print(f\"  Summary for '{class_name}': Removed={class_removed_dimension} (dimension), Error={class_error_reading} (read).\")\n",
    "        continue # Skip to the next class\n",
    "\n",
    "    print(f\"  Finished validation: Kept={len(valid_files)}, Removed={class_removed_dimension} (dimension), Error={class_error_reading} (read).\")\n",
    "\n",
    "    # --- Shuffle and Split Only Valid Files ---\n",
    "    random.shuffle(valid_files) # Shuffle in place\n",
    "    total_valid_files = len(valid_files)\n",
    "\n",
    "    # --- Calculate Split Sizes based on valid files ---\n",
    "    train_count = math.floor(total_valid_files * SPLIT_RATIOS['train'])\n",
    "    test_count = math.floor(total_valid_files * SPLIT_RATIOS['test'])\n",
    "    validate_count = max(0, total_valid_files - train_count - test_count) # Assign remainder to validate\n",
    "\n",
    "    # Adjust if rounding caused sum != total_valid_files\n",
    "    current_total = train_count + test_count + validate_count\n",
    "    if current_total < total_valid_files:\n",
    "         validate_count += (total_valid_files - current_total) # Add remainder to validate\n",
    "\n",
    "    print(f\"  Splitting {total_valid_files} valid images into: Train={train_count}, Test={test_count}, Validate={validate_count}\")\n",
    "\n",
    "    # --- Assign Files to Splits ---\n",
    "    split_files = {\n",
    "        'train': valid_files[0:train_count],\n",
    "        'test': valid_files[train_count : train_count + test_count],\n",
    "        'validate': valid_files[train_count + test_count : ]\n",
    "    }\n",
    "\n",
    "    # --- Copy Valid Files to Target Directories ---\n",
    "    files_copied_counts = {'train': 0, 'test': 0, 'validate': 0}\n",
    "    for split_name, files in split_files.items():\n",
    "        target_dir = target_dirs[split_name]\n",
    "        for filename in files:\n",
    "            # We already validated these files, so just copy\n",
    "            source_path = os.path.join(source_class_dir, filename)\n",
    "            target_path = os.path.join(target_dir, filename)\n",
    "            try:\n",
    "                shutil.copy2(source_path, target_path) # copy2 preserves metadata\n",
    "                files_copied_counts[split_name] += 1\n",
    "            except Exception as e:\n",
    "                 print(f\"    ERROR: Failed to copy {source_path} to {target_path}: {e}\")\n",
    "\n",
    "    print(f\"  Files copied: Train={files_copied_counts['train']}, Test={files_copied_counts['test']}, Validate={files_copied_counts['validate']}\")\n",
    "    \n",
    "    # Sanity check counts after potential copy errors\n",
    "    copied_total = sum(files_copied_counts.values())\n",
    "    expected_total = train_count + test_count + validate_count\n",
    "    if copied_total != expected_total:\n",
    "         print(f\"  NOTE: Copied {copied_total} files, expected {expected_total}. Check for copy errors above.\")\n",
    "\n",
    "\n",
    "# --- Final Report ---\n",
    "print(\"\\n\" + \"=\" * 30)\n",
    "print(\"Processing Complete!\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Total potential image files processed: {total_files_processed}\")\n",
    "print(f\"Total files removed (dimension mismatch): {total_files_removed_dimension}\")\n",
    "print(f\"Total files removed (error reading):    {total_files_error_reading}\")\n",
    "print(f\"Total valid files kept and split:       {total_files_kept}\")\n",
    "print(\"-\" * 30)\n",
    "if total_files_kept != (total_files_processed - total_files_removed_dimension - total_files_error_reading):\n",
    "     print(\"Warning: Discrepancy in file counts - check logs.\")\n",
    "print(f\"\\nDataset successfully split into Train/Test/Validate sets within the '{TARGET_BASE_DIR}' directory using only images with dimensions {EXPECTED_DIMS}.\")\n",
    "\n",
    "# Optional: Print details of removed files (can be long)\n",
    "# print(\"\\nDetails of removed/error files:\")\n",
    "# for path, reason, detail in removed_file_details:\n",
    "#     print(f\"  - {path} | Reason: {reason} | Details: {detail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27e0b2-fd13-4f0c-9c21-8f72a7050dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLproj",
   "language": "python",
   "name": "mlproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
